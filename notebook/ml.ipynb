{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poem Classification using Deep Learning  \n",
    "\n",
    "## üìå Project Overview  \n",
    "\n",
    "Poetry is a unique form of artistic expression, often encompassing deep emotions, vivid imagery, and rhythmic structures. This project aims to classify poems into one of four predefined genres using Natural Language Processing (NLP) and Deep Learning techniques.  \n",
    "\n",
    "The four poem genres included in the dataset are:  \n",
    "- **Affection** üíñ (Love, friendship, emotions)  \n",
    "- **Environment** üåø (Nature, seasons, landscapes)  \n",
    "- **Music** üéµ (Melody, rhythm, musical themes)  \n",
    "- **Death** ‚ö∞Ô∏è (Loss, grief, mortality)  \n",
    "\n",
    "We will build a deep learning model capable of understanding the thematic elements of poetry and classifying it into the appropriate genre.  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Objectives  \n",
    "\n",
    "- **Text Preprocessing**: Cleaning poetry texts by removing special characters, stopwords, and performing tokenization.  \n",
    "- **Feature Extraction**: Using word embeddings (Word2Vec, GloVe, or embeddings from Transformer models like BERT) to represent poems in a numerical format.  \n",
    "- **Model Training**: Training a deep learning model (LSTM, BiLSTM, or Transformer-based models) to classify poems.  \n",
    "- **Evaluation**: Assessing model performance using accuracy, F1-score, and confusion matrix.  \n",
    "- **Deployment**: Integrating the trained model into a **Flask web application** for real-time poem classification.  \n",
    "- **Model Tracking with MLflow**: Implementing **MLflow** to log experiment parameters, model performance, and facilitate reproducibility.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìú Dataset Details  \n",
    "\n",
    "The dataset consists of poetry texts labeled into four categories: **Affection, Environment, Music, and Death**. Each poem undergoes preprocessing steps such as:  \n",
    "\n",
    "- **Removing special characters & punctuation**  \n",
    "- **Lowercasing text**  \n",
    "- **Tokenization & stopword removal**  \n",
    "- **Using word embeddings for numerical representation**  \n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Model Training Workflow  \n",
    "\n",
    "1. **Data Preprocessing**: Cleaning the text data and converting words into numerical embeddings.  \n",
    "2. **Model Selection**: Experimenting with deep learning architectures like LSTM, BiLSTM, and Transformer-based models.  \n",
    "3. **Training & Hyperparameter Tuning**: Optimizing model performance by fine-tuning hyperparameters.  \n",
    "4. **Evaluation**: Comparing different models using evaluation metrics like accuracy, precision, recall, and F1-score.  \n",
    "5. **Logging with MLflow**: Tracking model experiments, storing trained models, and comparing performance metrics.  \n",
    "6. **Deployment**: Deploying the best-performing model as a **Flask web app** on **Render**.  \n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Technologies Used  \n",
    "\n",
    "- **Python (3.x)** üêç  \n",
    "- **TensorFlow/Keras** ü§ñ  \n",
    "- **NLTK / SpaCy** (For text preprocessing)  \n",
    "- **Word2Vec / GloVe / BERT** (For word embeddings)  \n",
    "- **LSTM / BiLSTM / Transformers** (Deep Learning models)  \n",
    "- **MLflow** (For experiment tracking)  \n",
    "- **Flask** (For web application)  \n",
    "- **Render** (For model deployment)  \n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps  \n",
    "\n",
    "- Experiment with **BERT embeddings** for improved contextual understanding.  \n",
    "- Compare performance with **CNN-based text classification models**.  \n",
    "- Implement **attention mechanisms** to improve classification accuracy.  \n",
    "- Deploy the model as an **interactive web app** for users to input poetry and get instant classification results.  \n",
    "\n",
    "---\n",
    "\n",
    "üí° **Let's get started with the Poem Classification project!** üöÄ  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "# make with this report \n",
    "import pandas_profiling\n",
    "\n",
    "# gnore all warnings\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing imports \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Alogrithim \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "# Hyperpearmeter turning \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "## model accuary metrices \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "## dorp the model in pickle \n",
    "import pickle\n",
    "\n",
    "## Tracking the Model \n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a DataFrame\n",
    "poem_df = pd.read_csv('D:\\\\Professional\\\\data\\\\Depression Professional Dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
